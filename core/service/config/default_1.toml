# Below is the configuration for the tkms service, usually this is the
# interface that the connector interacts with to submit requests and query for
# responses.
[service]

# IP address that the tcp listener binds on. This endpoint should not be
# exposed externally.
listen_address = "0.0.0.0"

# Port number that the tcp listener binds on.
listen_port = 50100

# The timeout in seconds for all GRPC request handlers.
timeout_secs = 360

# Maximum GRPC message size in bytes
grpc_max_message_size = 104857600 # 100 MiB

# Set the AWS region and endpoint used by [public_vault.storage]
# and/or [private_vault.storage], if the storage URL starts with "s3://"".
# If the storage URL is file-based, this configuration is ignored.
[aws]
region = "us-east-1"
s3_endpoint = "http://dev-s3-mock:9000"

# This is the storage backend for the public vault.
[public_vault]

# The storage URL. Two URL schemas are supported: file:// and s3://. The paths
# can be the same for the different storage types and for different parties.
[public_vault.storage.file]
path = "./keys"

# This is the storage backend for the private vault.
[private_vault.storage.file]

# The storage URL. Two URL schemas are supported: file:// and s3://. The paths
# can be the same for the different storage types and for different parties.
path = "./keys"

# If S3 storage is used for private keys, we recommend to run the Core within
# the Nitro enclave, so the risk of leaking them is less. Since Nitro enclaves
# do not have any persistent storage, private keys will be exported for
# long-term storage in an encrypted container after generation. The encryption
# mechanism is controlled by the keychain parameter.
#
# root_key_id is an AWS KMS key identifier for the root key to use during
# private key import and export to and from the Nitro enclave. The AWS KMS key
# policy for this root key should have only allow its use to known and attested
# versions of the Core. (Unset by default)
#
# [private_vault.keychain.aws_kms]
# root_key_id = "root_key_id"

# root_key_spec is an AWS KMS key spec for the root key (valid choices are
# "symm" and "asymm")
# root_key_spec = "symm"

# This is the storage backend up the backup vault.
# If configured, most operations that writes to the private vault
# will also be written to the backup vault.
# We do not write PrssState to the backup vault since it can be regenerated easily
[backup_vault]
[backup_vault.storage.file]
path = "./backup_vault"

# The section below contains the relevant configuration for communicating with
# other TKMS nodes. This section is not needed when running TKMS in the
# centralized mode.
[threshold]

# The address and port that tcp listener binds on to
# communicate with the other cores. The listen_port
# cannot be the same as the listen_port under [service].
listen_address = "0.0.0.0"
listen_port = 50001

# The identity of myself, this number must be unique.
my_id = 1

# Threshold is the number of corruptions that the protocol handles. Currently
# it must be an integer less than parties/3.
threshold = 1

# The amount of decryption, respectively public/user decryption, queries to be able to
# cache. That is, the total sum of requests to hold in RAM, including completed
# and on-going requests.
dec_capacity = 10000

# The minimum amount of completed decryption, respectively public/user decryption,
# queries to cache. That is, once the system is fully saturated with queries,
# i.e. going above dec_capacity then old and completed queries will be removed
# from memory, starting with the oldest. The min_dec_cache is the minimum
# amount of completed queries to keep cached. Hence once the system has been
# saturated, the maximum amount of ongoing queries to have in the system is
# dec_capacity-min_dec_cache.
min_dec_cache = 6000

# The amount of on-going preprocessing sessions to execute simultaneously while
# doing preprocessing for key generation. Observe that 2 sessions is the
# minimum since one will take care of triple and randomness generation and one
# will take care of bit preprocessing.
num_sessions_preproc = 2

# The type of decryption protocol to run. Available types: NoiseFloodSmall or BitDecSmall
decryption_mode = "NoiseFloodSmall"

# Paths to optional TLS certificate and private key in the PEM
# encoding. Alternatively, multiline blocks with PEM-formatted content. This is
# used to establish mutual authentication with other cores.
[threshold.tls.manual]
cert.path = "certs/cert_p1.pem"
key.path = "certs/key_p1.pem"

# Every core/service needs to be aware of all other core/services. In the
# future there should be an option to load this configuration from a blockchain
# smart contract. At the moment they need to be loaded from the same
# configuration file.
#
# The number of [[threshold.peers]] dictates the total number of parties. This
# list should be the same for all parties. Addresses and ports below are for
# communicating with the cores to perform MPC tasks.
#
# The field `mpc_identity` is used to identify the core in the MPC protocol.
# It must match the subject common name (CN) in the TLS certificate.
# This is how cores authenticate each other in the MPC protocol,
# i.e., party-2 connecting to party-1 must prove that it is indeed party-2
# and not any other party that's in the list of TLS certificates.
# If it is not configured it default to the `address` field.
#
# NOTE: in the future the peer list will be removed and loaded from the context.
# See zama-ai/kms-internal#2530
[[threshold.peers]]
party_id = 1
address = "p1"
mpc_identity = "p1"
port = 50001
tls_cert.path = "certs/cert_p1.pem"

[[threshold.peers]]
party_id = 2
address = "p2"
mpc_identity = "p2"
port = 50002
tls_cert.path = "certs/cert_p2.pem"

[[threshold.peers]]
party_id = 3
address = "p3"
mpc_identity = "p3"
port = 50003
tls_cert.path = "certs/cert_p3.pem"

[[threshold.peers]]
party_id = 4
address = "p4"
mpc_identity = "p4"
port = 50004
tls_cert.path = "certs/cert_p4.pem"

# Specify the network configuration of the core-to-core communication
# Values below are the same as the one in the constant file for the core network
# This is optional, and falls back to constant file if not provided.
[threshold.core_to_core_net]
message_limit = 70
multiplier = 2.0
max_interval = 60
initial_interval_ms = 100
max_elapsed_time = 300
network_timeout = 20
network_timeout_bk = 300
network_timeout_bk_sns = 1200
max_en_decode_message_size = 2147483648
session_update_interval_secs = 60
session_cleanup_interval_secs = 3600
discard_inactive_sessions_interval = 900
max_waiting_time_for_message_queue = 60
max_opened_inactive_sessions_per_party = 100

# The address of the redis instance that will hold the preprocessed material
# for use in key generation. (Unset by default)
# [threshold.preproc_redis]
# host = "redis://127.0.0.1"
#

[telemetry]
tracing_service_name = "kms-threshold-1"
# tracing_endpoint = "http://localhost:4317"
tracing_otlp_timeout_ms = 10000
metrics_bind_address = "0.0.0.0:9646"
enable_sys_metrics = true

[telemetry.batch]
max_queue_size = 8192
max_export_batch_size = 2048
scheduled_delay_ms = 500

# Optional rate limiting configuration. All parties **must** use the same
# configuration, even on different hardware, to avoid diverging behavior which
# could lead to uncontrolled issues the MPC protocol. The `bucket_size`
# represents the total amount of tokens available for processing in the core.
# The fields other fields represents the price of each operation in the core.
# I.e. how many tokens will be taken while the operation is executing. If all
# tokens are in use then the core will refuse further operations until a
# sufficient amount of tokens are released.
[rate_limiter_conf]
bucket_size = 50000
pub_decrypt = 1
user_decrypt = 1
crsgen = 100
preproc = 25000
keygen = 1000
