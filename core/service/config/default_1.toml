# Below is the configuration for the tkms service, usually this is the
# interface that the connector interacts with to submit requests and query for
# responses.
[service]

# IP address that the tcp listener binds on. This endpoint should not be
# exposed externally.
listen_address = "0.0.0.0"

# Port number that the tcp listener binds on.
listen_port = 50100

# The timeout in seconds for all GRPC request handlers.
timeout_secs = 360

# Maximum GRPC message size in bytes
grpc_max_message_size = 104857600 # 100 MiB

# Set the AWS region and endpoint used by [public_vault.storage]
# and/or [private_vault.storage], if the storage URL starts with "s3://"".
# If the storage URL is file-based, this configuration is ignored.
[aws]
region = "us-east-1"
s3_endpoint = "http://dev-s3-mock:9000"

# This is the storage backend for the public vault.
[public_vault]

# The storage URL. Two URL schemas are supported: file:// and s3://. The paths
# can be the same for the different storage types and for different parties.
storage = "file://./keys"

# This is the storage backend for the private vault.
[private_vault]

# The storage URL. Two URL schemas are supported: file:// and s3://. The paths
# can be the same for the different storage types and for different parties.
storage = "file://./keys"

# If S3 storage is used for private keys, we recommend to run the Core within
# the Nitro enclave, so the risk of leaking them is less. Since Nitro enclaves
# do not have any persistent storage, private keys will be exported for
# long-term storage in an encrypted container after generation. The encryption
# mechanism is controlled by the keychain parameter.
#
# root_key_id is an AWS KMS key identifier for the root key to use during
# private key import and export to and from the Nitro enclave. The AWS KMS key
# policy for this root key should have only allow its use to known and attested
# versions of the Core. (Unset by default)
# keychain = "awskms://root_key_id"

# The section below contains the relevant configuration for communicating with
# other TKMS nodes. This section is not needed when running TKMS in the
# centralized mode.
[threshold]

# The address and port that tcp listener binds on to
# communicate with the other cores. The listen_port
# cannot be the same as the listen_port under [service].
listen_address = "0.0.0.0"
listen_port = 50001

# The identity of myself, this number must be unique.
my_id = 1

# Threshold is the number of corruptions that the protocol handles. Currently
# it must be an integer less than parties/3.
threshold = 1

# The amount of decryption, respectively reencryption, queries to be able to
# cache. That is, the total sum of requests to hold in RAM, including completed
# and on-going requests.
dec_capacity = 10000

# The minimum amount of completed decryption, respectively reencryption,
# queries to cache. That is, once the system is fully saturated with queries,
# i.e. going above dec_capacity then old and completed queries will be removed
# from memory, starting with the oldest. The min_dec_cache is the minimum
# amount of completed queries to keep cached. Hence once the system has been
# saturated, the maximum amount of ongoing queries to have in the system is
# dec_capacity-min_dec_cache.
min_dec_cache = 6000

# The amount of on-going preprocessing sessions to execute simultaneously while
# doing preprocessing for key generation. Observe that 2 sessions is the
# minimum since one will take care of triple and randomness generation and one
# will take care of bit preprocessing.
num_sessions_preproc = 2

# Path to optional TLS certificate and private key in the PEM encoding. This is
# to used to establish mutual authentication with other cores.
tls_cert_path = "certs/cert_p1.pem"
tls_key_path = "certs/key_p1.pem"

# The type of decryption protocol to run. Available types: NoiseFloodSmall or BitDecSmall
decryption_mode = "NoiseFloodSmall"

# Every core/service needs to be aware of all other core/services. In the
# future there should be an option to load this configuration from a blockchain
# smart contract. At the moment they need to be loaded from the same
# configuration file.
#
# The number of [[threshold.peers]] dictates the total number of parties. This
# list should be the same for all parties. Addresses and ports below are for
# communicating with the cores to perform MPC tasks.
[[threshold.peers]]
party_id = 1
address = "p1"
port = 50001
tls_cert_path = "certs/cert_p1.pem"

[[threshold.peers]]
party_id = 2
address = "p2"
port = 50002
tls_cert_path = "certs/cert_p2.pem"

[[threshold.peers]]
party_id = 3
address = "p3"
port = 50003
tls_cert_path = "certs/cert_p3.pem"

[[threshold.peers]]
party_id = 4
address = "p4"
port = 50004
tls_cert_path = "certs/cert_p4.pem"

# Specify the network configuration of the core-to-core communication
# Values below are the same as the one in the constant file for the core network
# This is optional, and falls back to constant file if not provided.
[threshold.core_to_core_net]
message_limit = 70
multiplier = 1.1
max_interval = 5
max_elapsed_time = 300
network_timeout = 10
network_timeout_bk = 300
network_timeout_bk_sns = 1200
max_en_decode_message_size = 2147483648

# The address of the redis instance that will hold the preprocessed material
# for use in key generation. (Unset by default)
# [threshold.preproc_redis]
# host = "redis://127.0.0.1"
#

[telemetry]
tracing_service_name = "kms-threshold-1"
# tracing_endpoint = "http://localhost:4317"
tracing_otlp_timeout_ms = 10000
metrics_bind_address = "0.0.0.0:9646"

[telemetry.batch]
max_queue_size = 8192
max_export_batch_size = 2048
max_concurrent_exports = 4
scheduled_delay_ms = 500
export_timeout_ms = 5000

# Optional rate limiting configuration. All parties **must** use the same
# configuration, even on different hardware, to avoid diverging behaviour which
# could lead to uncontrolled issues the MPC protocol. The `bucket_size`
# represents the total amount of tokens available for processing in the core.
# The fields other fields represents the price of each operation in the core.
# I.e. how many tokens will be taken while the operation is executing. If all
# tokens are in use then the core will refuse further operations until a
# sufficient amount of tokens are released.
[rate_limiter_conf]
bucket_size = 50000
dec = 1
reenc = 1
crsgen = 100
preproc = 5000
keygen = 1000
verify_proven_ct = 1
